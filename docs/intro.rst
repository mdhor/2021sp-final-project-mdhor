
Introduction
============

Pricing and assortment data is highly valuable but can be difficult and expensive to obtain, especially for smaller retailers.

Because of digitalization, the importance of pricing and assortment data has increased. An insight into a companys online presence is crucial for success.
This is especially true after COVID-19, where smaller retailers are forced to differentiate themselves online.
Without large IT-budgets, gaining good data surrounding ones own as well as competitors pricing and assortment can be difficult.

Data on pricing and assortment can be used for several insightful analyses. One example is pricing analysis to answer questions like "Where do our prices differ from competitors?".
Another example is assortment analysis; "How does our assortment compare to competitors?".

prisjakt.no is a leading actor within price comparison in Norway. It acts as an "all-inclusive" shopping mall, so the consumer does not have to browse many different website, by comparing pricing
from many different retailers. The products range widely from electronics, to clothing, to vehicles.



Quick-Start
-------------------------------------

If you want to test the project quickly, first clone the repo and create an environment using the Pipfile.
Then execute the following commands:

   .. code-block:: bash

      pipenv run python manage.py migrate
      pipenv run python -m final_project
      pipenv run python manage.py runserver

Now you can open the server and check out a visual.





Aim of Project
-------------------------------------

The project aims to create a full stack data science pipeline, from mining prisjakt.no data all the way to showing results in a web application.
The project can be split into four main workflows:

#.  Developing pj-scraper, a library that will act as a simplified interface for scraping of prisjakt.no

#.  Organizing the pipeline into Luigi Tasks, all the way from handling scraping to appending data in a Django database

#.  Creating a Django database that will contain the data that has been scraped from prisjakt.no

#.  Developing a simple Django web app to show a simple example of how the data can be used for analysis



High-Level Workflow
----------------------------------


.. image:: ./images/workflow.png
  :width: 800





Autogeneration of the Documentation
-------------------------------------

To autogenerate the documentation i did the following three things:

#.  Link ReadTheDocs with the Github repo, so a new RTD build will be executed on every new commit

#.  Add a requirements.txt to the docs/ directory, to enable RTD to create the documentation within the right environment

#.  Run sphinx-apidoc from within docs/conf.py, so that apidoc will run before the html output is created (although this is a cool feature, I decided not to use it in the end, but I've left it in for others to learn)

It should be noted that some of the autogenerated docs are blank because csci_utils can't be installed, because it is a private repo.
